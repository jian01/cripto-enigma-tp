{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "continental-medicare",
   "metadata": {},
   "outputs": [],
   "source": [
    "from enigma.enigma import Enigma\n",
    "from enigma.rotors.rotor_with_mapping_and_notches import RotorWithMappingAndNotches\n",
    "from enigma.rotors.rotor_I import RotorI\n",
    "from enigma.rotors.rotor_II import RotorII\n",
    "from enigma.rotors.rotor_III import RotorIII\n",
    "from enigma.rotors.rotor_IV import RotorIV\n",
    "from enigma.rotors.rotor_V import RotorV\n",
    "from enigma.reflectors.reflector_b import ReflectorB\n",
    "from enigma.plugboard import Plugboard\n",
    "from language_models.character_frequency_kld_language_model import CharacterFrequencyKLDLanguageModel\n",
    "from language_models.markov_chain_model import MarkovChainModel\n",
    "from language_models.character_frequency_ic_language_model import CharacterFrequencyICLanguageModel\n",
    "\n",
    "import timeit, time, random, pickle\n",
    "from collections import defaultdict\n",
    "from statistics import mean\n",
    "from itertools import permutations, combinations\n",
    "from tqdm import tqdm\n",
    "from tqdm.auto import trange\n",
    "from multiprocessing import Pool\n",
    "from functools import partial\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "later-smart",
   "metadata": {},
   "outputs": [],
   "source": [
    "POSSIBLE_ROTORS = {RotorI, RotorII, RotorIII, RotorIV, RotorV}\n",
    "POSSIBLE_LETTERS = \"ABCDEFGHIJKLMNOPQRSTUVWXYZ\"\n",
    "\n",
    "def get_random_plugboad(plugboard_size: int):\n",
    "    letter_sample = random.sample(list(POSSIBLE_LETTERS), plugboard_size*2)\n",
    "    plugboard_tuples = []\n",
    "    for i in range(len(letter_sample)//2):\n",
    "        plugboard_tuples.append((letter_sample[i*2], letter_sample[(i*2)+1]))\n",
    "    plugboard_tuples = sorted(plugboard_tuples, key=lambda x: x[0])\n",
    "    return plugboard_tuples\n",
    "\n",
    "def get_random_config(plugboard_size: int):\n",
    "    rotors_to_use = random.sample(POSSIBLE_ROTORS, 3)\n",
    "    offsets = [random.randint(0,25) for _ in range(3)]\n",
    "    plugboard_tuples = get_random_plugboad(plugboard_size)\n",
    "    return rotors_to_use, offsets, plugboard_tuples\n",
    "\n",
    "def string_to_config(string: str):\n",
    "    match = re.findall(\"(.+)\\(o:(\\d+),rs:(\\d+)\\)\\|(.+)\\(o:(\\d+),rs:(\\d+)\\)\\|(.+)\\(o:(\\d+),rs:(\\d+)\\)\\|(.*)\", \n",
    "                       string, re.IGNORECASE)[0]\n",
    "    available_rotors = {rot.__name__:rot for rot in RotorWithMappingAndNotches.__subclasses__()}\n",
    "    rotors_classes = [available_rotors[match[0]], available_rotors[match[3]], available_rotors[match[6]]]\n",
    "    offsets = [int(match[1]), int(match[4]), int(match[7])]\n",
    "    ringstellungs = [int(match[2]), int(match[5]), int(match[8])]\n",
    "    plugboard_tuples = []\n",
    "    for i in range(len(match[9])//2):\n",
    "        plugboard_tuples.append((match[9][i*2],match[9][(i*2)+1]))\n",
    "    return rotors_classes, offsets, ringstellungs, plugboard_tuples\n",
    "\n",
    "def config_to_string(rotors_classes, offsets, plugboard_tuples):\n",
    "    string = \"\"\n",
    "    for rot, off in zip(rotors_classes, offsets):\n",
    "        string += rot.__name__+\"(o:%d)\"%(off)+\"|\"\n",
    "    for l1, l2 in plugboard_tuples:\n",
    "        string += l1+l2\n",
    "    return string\n",
    "\n",
    "def transform_to_valid_chars(text: str):\n",
    "    text = text.upper()\n",
    "    return \"\".join([c for c in text if c in POSSIBLE_LETTERS])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "cosmetic-local",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'RotorII(o:20)|RotorIV(o:2)|RotorI(o:21)|AGDLFQIZKSMBNXOEUWVP'"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Me defino una enigma\n",
    "PLUGBOARD_SIZE = 10 #Size used by Germany in WW2\n",
    "rotors, offsets, plugboard_tuples = get_random_config(PLUGBOARD_SIZE)\n",
    "rotors_to_use = [rot_c(offset=off) \n",
    "                 for rot_c, off in zip(rotors, offsets)]\n",
    "enigma = Enigma(reflector=ReflectorB(),\n",
    "                        plugboard=Plugboard(plugboard_tuples),\n",
    "                        rotors=rotors_to_use)\n",
    "config_to_string(rotors, offsets, plugboard_tuples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "serial-dietary",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelo de lenguaje basado en la frecuencia de caracteres en un libro en ingles\n",
    "with open('books/Alices_Adventures_in_Wonderland.txt', 'r') as book:\n",
    "    train_book = book.read()\n",
    "freq_kld_model = CharacterFrequencyKLDLanguageModel(train_book)\n",
    "markov_1_model = MarkovChainModel(train_book)\n",
    "ic_model = CharacterFrequencyICLanguageModel(train_book)\n",
    "\n",
    "with open('books/Frankenstein.txt', 'r') as book:\n",
    "    frankestein_book = transform_to_valid_chars(book.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "turkish-harbor",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Todos los datos referidos a tiempos\n",
    "time_kl, time_markov_1, time_ic = defaultdict(list), defaultdict(list), defaultdict(list)\n",
    "time_enigma = defaultdict(list) # Tambien me voy a fijar cuanto tarda la enigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "flush-needle",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Me genero todas las posibles combinaciones de los offsets de los rotores, para dos modelos distintos\n",
    "def crack(encrypted_message):\n",
    "    kl_divs, markov_1_divs, ic_divs = {}, {}, {}\n",
    "    length = len(encrypted_message)\n",
    "    \n",
    "    #for offsets in tqdm(range(26**3), total=26**3):\n",
    "    for i in range(26**3):\n",
    "        off1 = i % 26\n",
    "        off2 = (i//26) % 26\n",
    "        off3 = (i//(26**2)) % 26\n",
    "        enigma_with_given_offset = Enigma(ReflectorB(),\n",
    "                                          plugboard=Plugboard(plugboard_tuples),\n",
    "                                          rotors= [rot_c(offset=off) \n",
    "                                                   for rot_c, off in zip(rotors, [off1, off2, off3])]\n",
    "                                         )\n",
    "        start_time = timeit.default_timer()\n",
    "        decrypted_message = enigma_with_given_offset.decrypt(encrypted_message)\n",
    "        time_enigma[length].append(timeit.default_timer() - start_time)\n",
    "    \n",
    "        start_time = timeit.default_timer()\n",
    "        kl_divs[(off1, off2, off3)] = freq_kld_model.fitness(decrypted_message)\n",
    "        time_kl[length].append(timeit.default_timer() - start_time)\n",
    "        \n",
    "        start_time = timeit.default_timer()\n",
    "        markov_1_divs[(off1, off2, off3)] = markov_1_model.fitness(decrypted_message)\n",
    "        time_markov_1[length].append(timeit.default_timer() - start_time)\n",
    "                \n",
    "        start_time = timeit.default_timer()\n",
    "        ic_divs[(off1, off2, off3)] = ic_model.fitness(decrypted_message)\n",
    "        time_ic[length].append(timeit.default_timer() - start_time)\n",
    "            \n",
    "    kl_divs = sorted(kl_divs.items(), key=lambda x: x[1], reverse = True)\n",
    "    markov_1_divs = sorted(markov_1_divs.items(), key=lambda x: x[1], reverse = True)\n",
    "    ic_divs = sorted(ic_divs.items(), key=lambda x: x[1], reverse = True)\n",
    "  \n",
    "    return kl_divs, markov_1_divs, ic_divs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "civil-profile",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/9 [00:00<?, ?it/s]\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 10%|█         | 1/10 [00:23<03:34, 23.86s/it]\u001b[A\n",
      " 20%|██        | 2/10 [00:48<03:12, 24.04s/it]\u001b[A\n",
      " 30%|███       | 3/10 [01:11<02:47, 23.94s/it]\u001b[A\n",
      " 40%|████      | 4/10 [01:35<02:23, 23.92s/it]\u001b[A\n",
      " 50%|█████     | 5/10 [02:00<02:00, 24.15s/it]\u001b[A\n",
      " 60%|██████    | 6/10 [02:23<01:34, 23.74s/it]\u001b[A\n",
      " 70%|███████   | 7/10 [02:47<01:11, 23.78s/it]\u001b[A\n",
      " 80%|████████  | 8/10 [03:10<00:47, 23.80s/it]\u001b[A\n",
      " 90%|█████████ | 9/10 [03:34<00:23, 23.85s/it]\u001b[A\n",
      "100%|██████████| 10/10 [03:58<00:00, 23.87s/it]\u001b[A\n",
      " 11%|█         | 1/9 [03:58<31:49, 238.70s/it]\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 10%|█         | 1/10 [00:24<03:38, 24.32s/it]\u001b[A\n",
      " 20%|██        | 2/10 [00:48<03:16, 24.51s/it]\u001b[A\n",
      " 30%|███       | 3/10 [01:12<02:49, 24.19s/it]\u001b[A\n",
      " 40%|████      | 4/10 [01:37<02:26, 24.35s/it]\u001b[A\n",
      " 50%|█████     | 5/10 [02:01<02:01, 24.38s/it]\u001b[A\n",
      " 60%|██████    | 6/10 [02:25<01:36, 24.12s/it]\u001b[A\n",
      " 70%|███████   | 7/10 [02:49<01:12, 24.24s/it]\u001b[A\n",
      " 80%|████████  | 8/10 [03:14<00:48, 24.25s/it]\u001b[A\n",
      " 90%|█████████ | 9/10 [03:38<00:24, 24.34s/it]\u001b[A\n",
      "100%|██████████| 10/10 [04:02<00:00, 24.29s/it]\u001b[A\n",
      " 22%|██▏       | 2/9 [08:01<28:08, 241.20s/it]\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 10%|█         | 1/10 [00:26<03:55, 26.17s/it]\u001b[A\n",
      " 20%|██        | 2/10 [00:51<03:23, 25.50s/it]\u001b[A\n",
      " 30%|███       | 3/10 [01:16<02:56, 25.28s/it]\u001b[A\n",
      " 40%|████      | 4/10 [01:42<02:33, 25.59s/it]\u001b[A\n",
      " 50%|█████     | 5/10 [02:10<02:12, 26.46s/it]\u001b[A\n",
      " 60%|██████    | 6/10 [02:35<01:44, 26.20s/it]\u001b[A\n",
      " 70%|███████   | 7/10 [03:00<01:17, 25.72s/it]\u001b[A\n",
      " 80%|████████  | 8/10 [03:25<00:50, 25.44s/it]\u001b[A\n",
      " 90%|█████████ | 9/10 [03:51<00:25, 25.49s/it]\u001b[A\n",
      "100%|██████████| 10/10 [04:15<00:00, 25.58s/it]\u001b[A\n",
      " 33%|███▎      | 3/9 [12:17<24:47, 247.88s/it]\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 10%|█         | 1/10 [00:27<04:05, 27.33s/it]\u001b[A\n",
      " 20%|██        | 2/10 [00:52<03:27, 25.93s/it]\u001b[A\n",
      " 30%|███       | 3/10 [01:17<02:59, 25.59s/it]\u001b[A\n",
      " 40%|████      | 4/10 [01:42<02:31, 25.27s/it]\u001b[A\n",
      " 50%|█████     | 5/10 [02:07<02:05, 25.11s/it]\u001b[A\n",
      " 60%|██████    | 6/10 [02:31<01:39, 24.95s/it]\u001b[A\n",
      " 70%|███████   | 7/10 [02:56<01:14, 24.89s/it]\u001b[A\n",
      " 80%|████████  | 8/10 [03:22<00:50, 25.40s/it]\u001b[A\n",
      " 90%|█████████ | 9/10 [03:50<00:26, 26.03s/it]\u001b[A\n",
      "100%|██████████| 10/10 [04:16<00:00, 25.66s/it]\u001b[A\n",
      " 44%|████▍     | 4/9 [16:34<20:56, 251.31s/it]\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 10%|█         | 1/10 [00:25<03:51, 25.70s/it]\u001b[A\n",
      " 20%|██        | 2/10 [00:51<03:25, 25.74s/it]\u001b[A\n",
      " 30%|███       | 3/10 [01:18<03:03, 26.23s/it]\u001b[A\n",
      " 40%|████      | 4/10 [01:44<02:36, 26.09s/it]\u001b[A\n",
      " 50%|█████     | 5/10 [02:11<02:12, 26.51s/it]\u001b[A\n",
      " 60%|██████    | 6/10 [02:37<01:45, 26.33s/it]\u001b[A\n",
      " 70%|███████   | 7/10 [03:03<01:18, 26.16s/it]\u001b[A\n",
      " 80%|████████  | 8/10 [03:28<00:51, 25.94s/it]\u001b[A\n",
      " 90%|█████████ | 9/10 [03:54<00:25, 25.96s/it]\u001b[A\n",
      "100%|██████████| 10/10 [04:20<00:00, 26.05s/it]\u001b[A\n",
      " 56%|█████▌    | 5/9 [20:54<16:58, 254.62s/it]\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 10%|█         | 1/10 [00:26<03:55, 26.18s/it]\u001b[A\n",
      " 20%|██        | 2/10 [00:52<03:30, 26.30s/it]\u001b[A\n",
      " 30%|███       | 3/10 [01:18<03:03, 26.24s/it]\u001b[A\n",
      " 40%|████      | 4/10 [01:45<02:39, 26.59s/it]\u001b[A\n",
      " 50%|█████     | 5/10 [02:12<02:12, 26.47s/it]\u001b[A\n",
      " 60%|██████    | 6/10 [02:38<01:46, 26.60s/it]\u001b[A\n",
      " 70%|███████   | 7/10 [03:05<01:19, 26.48s/it]\u001b[A\n",
      " 80%|████████  | 8/10 [03:32<00:53, 26.86s/it]\u001b[A\n",
      " 90%|█████████ | 9/10 [03:59<00:26, 26.87s/it]\u001b[A\n",
      "100%|██████████| 10/10 [04:25<00:00, 26.59s/it]\u001b[A\n",
      " 67%|██████▋   | 6/9 [25:20<12:55, 258.46s/it]\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 10%|█         | 1/10 [00:26<04:01, 26.78s/it]\u001b[A\n",
      " 20%|██        | 2/10 [00:53<03:34, 26.87s/it]\u001b[A\n",
      " 30%|███       | 3/10 [01:21<03:10, 27.17s/it]\u001b[A\n",
      " 40%|████      | 4/10 [01:50<02:46, 27.83s/it]\u001b[A\n",
      " 50%|█████     | 5/10 [02:17<02:19, 27.83s/it]\u001b[A\n",
      " 60%|██████    | 6/10 [02:46<01:51, 27.93s/it]\u001b[A\n",
      " 70%|███████   | 7/10 [03:14<01:24, 28.11s/it]\u001b[A\n",
      " 80%|████████  | 8/10 [03:41<00:55, 27.69s/it]\u001b[A\n",
      " 90%|█████████ | 9/10 [04:08<00:27, 27.46s/it]\u001b[A\n",
      "100%|██████████| 10/10 [04:35<00:00, 27.56s/it]\u001b[A\n",
      " 78%|███████▊  | 7/9 [29:56<08:48, 264.09s/it]\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 10%|█         | 1/10 [00:27<04:08, 27.65s/it]\u001b[A\n",
      " 20%|██        | 2/10 [00:55<03:42, 27.85s/it]\u001b[A\n",
      " 30%|███       | 3/10 [01:23<03:14, 27.77s/it]\u001b[A\n",
      " 40%|████      | 4/10 [01:51<02:46, 27.76s/it]\u001b[A\n",
      " 50%|█████     | 5/10 [02:19<02:19, 27.83s/it]\u001b[A\n",
      " 60%|██████    | 6/10 [02:47<01:51, 27.98s/it]\u001b[A\n",
      " 70%|███████   | 7/10 [03:15<01:23, 27.91s/it]\u001b[A\n",
      " 80%|████████  | 8/10 [03:42<00:55, 27.86s/it]\u001b[A\n",
      " 90%|█████████ | 9/10 [04:10<00:27, 27.76s/it]\u001b[A\n",
      "100%|██████████| 10/10 [04:38<00:00, 27.82s/it]\u001b[A\n",
      " 89%|████████▉ | 8/9 [34:34<04:28, 268.58s/it]\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 10%|█         | 1/10 [00:28<04:12, 28.07s/it]\u001b[A\n",
      " 20%|██        | 2/10 [00:56<03:44, 28.06s/it]\u001b[A\n",
      " 30%|███       | 3/10 [01:24<03:18, 28.34s/it]\u001b[A\n",
      " 40%|████      | 4/10 [01:54<02:52, 28.78s/it]\u001b[A\n",
      " 50%|█████     | 5/10 [02:22<02:22, 28.56s/it]\u001b[A\n",
      " 60%|██████    | 6/10 [02:50<01:53, 28.46s/it]\u001b[A\n",
      " 70%|███████   | 7/10 [03:20<01:26, 28.86s/it]\u001b[A\n",
      " 80%|████████  | 8/10 [03:50<00:58, 29.31s/it]\u001b[A\n",
      " 90%|█████████ | 9/10 [04:20<00:29, 29.43s/it]\u001b[A\n",
      "100%|██████████| 10/10 [04:48<00:00, 28.85s/it]\u001b[A\n",
      "100%|██████████| 9/9 [39:22<00:00, 262.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 31min 46s, sys: 2.97 s, total: 31min 49s\n",
      "Wall time: 39min 22s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Para cada longitud, pruebo los diferentes modelos para los diferentes tipos de rotores\n",
    "\n",
    "MIN_LEN, MAX_LEN, STEP_LEN = 50, 105, 5\n",
    "MIN_LEN, MAX_LEN, STEP_LEN = 5, 50, 5\n",
    "NUMBER_OF_SAMPLES = 10\n",
    "\n",
    "crack_time_given_length = defaultdict(list)\n",
    "rankings_freq, rankings_markov_1, rankings_ic = defaultdict(list), defaultdict(list), defaultdict(list)\n",
    "\n",
    "for length in tqdm(range(MIN_LEN, MAX_LEN, STEP_LEN)):\n",
    "    print(length)\n",
    "#for length in tqdm(range(50, 51)):\n",
    "    #for _ in tqdm(range(1)):\n",
    "    for _ in tqdm(range(NUMBER_OF_SAMPLES)):\n",
    "        \n",
    "        start = random.randint(0, len(frankestein_book)-length) #Para que si o si tenga lenght \n",
    "        encrypted_message = enigma.encrypt(frankestein_book[start: start + length])\n",
    "        #print(\"Original: \", frankestein_book[start: start + length])\n",
    "        start_time_of_crack = timeit.default_timer()\n",
    "        kl_divs, markov_1_divs, ic_divs = crack(encrypted_message)\n",
    "        \n",
    "        first = lambda a: [x[0] for x in a] #Saca la primer componente de una lista de pares\n",
    "        \n",
    "        kl_divs_rots, markov_1_rots, ic_rots = first(kl_divs), first(markov_1_divs), first(ic_divs)\n",
    "        \n",
    "        crack_time_given_length[length].append(timeit.default_timer() - start_time_of_crack)\n",
    "        #print(\"A dormir\")\n",
    "        time.sleep(5) # Sleep de 5 segundos para poder bajarle la temperatura al procesador\n",
    "        \n",
    "        rankings_freq[length].append(kl_divs_rots.index(tuple(offsets)))\n",
    "        rankings_markov_1[length].append(markov_1_rots.index(tuple(offsets)))\n",
    "        rankings_ic[length].append(ic_rots.index(tuple(offsets)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "mineral-synthetic",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_time_kl = {k: mean(time_kl[k]) for k in time_kl}\n",
    "avg_time_markov_1 = {k: mean(time_markov_1[k]) for k in time_markov_1}\n",
    "avg_time_ic = {k: mean(time_ic[k]) for k in time_ic}\n",
    "avg_time_enigma = {k: mean(time_enigma[k]) for k in time_enigma}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "accompanied-breakfast",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_dump = (rankings_freq, rankings_markov_1, rankings_ic, crack_time_given_length, avg_time_kl, avg_time_markov_1, avg_time_ic, avg_time_enigma)\n",
    "with open('data_pickle_0_50.pkl', 'wb') as pickle_file:\n",
    "    pickle.dump(to_dump, pickle_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "recognized-turtle",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len: 50\n",
      " kl: 1.2\n",
      " markov_1: 83.1\n",
      " ic: 162.5\n",
      " crack_time: 22.83364073540015\n",
      "\n",
      "len: 55\n",
      " kl: 22.3\n",
      " markov_1: 1008.2\n",
      " ic: 738.3\n",
      " crack_time: 23.19803240729998\n",
      "\n",
      "len: 60\n",
      " kl: 1.3\n",
      " markov_1: 233.5\n",
      " ic: 62.3\n",
      " crack_time: 23.813124938700277\n",
      "\n",
      "len: 65\n",
      " kl: 0.7\n",
      " markov_1: 1593.8\n",
      " ic: 236.8\n",
      " crack_time: 24.25671641199988\n",
      "\n",
      "len: 70\n",
      " kl: 0.9\n",
      " markov_1: 617\n",
      " ic: 13.8\n",
      " crack_time: 24.75974554289969\n",
      "\n",
      "len: 75\n",
      " kl: 0.1\n",
      " markov_1: 610.9\n",
      " ic: 15.8\n",
      " crack_time: 25.378236897399983\n",
      "\n",
      "len: 80\n",
      " kl: 0\n",
      " markov_1: 299.9\n",
      " ic: 2.2\n",
      " crack_time: 26.64112117610002\n",
      "\n",
      "len: 85\n",
      " kl: 0\n",
      " markov_1: 155.6\n",
      " ic: 1.5\n",
      " crack_time: 29.36585634280018\n",
      "\n",
      "len: 90\n",
      " kl: 0.4\n",
      " markov_1: 437.4\n",
      " ic: 0.1\n",
      " crack_time: 27.034849198099984\n",
      "\n",
      "len: 95\n",
      " kl: 0\n",
      " markov_1: 58\n",
      " ic: 0.2\n",
      " crack_time: 30.14704999609985\n",
      "\n",
      "len: 100\n",
      " kl: 0.3\n",
      " markov_1: 1447.7\n",
      " ic: 0\n",
      " crack_time: 28.66607158820043\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open('data_pickle.pkl', 'rb') as pickle_file:\n",
    "    data = pickle.load(pickle_file)\n",
    "data\n",
    "\n",
    "avg_ranking_freq = {k: mean(rankings_freq[k]) for k in rankings_freq}\n",
    "avg_ranking_markov_1 = {k: mean(rankings_markov_1[k]) for k in rankings_markov_1}\n",
    "avg_ranking_ic = {k: mean(rankings_ic[k]) for k in rankings_ic}\n",
    "avg_crack_time = {k: mean(crack_time_given_length[k]) for k in crack_time_given_length}\n",
    "\n",
    "for i in range(MIN_LEN, MAX_LEN, STEP_LEN):\n",
    "    print(\"len: {}\\n kl: {}\\n markov_1: {}\\n ic: {}\\n crack_time: {}\\n\".format(i, avg_ranking_freq[i], avg_ranking_markov_1[i], avg_ranking_ic[i], avg_crack_time[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "superb-bahrain",
   "metadata": {},
   "outputs": [],
   "source": [
    "rankings_freq, rankings_markov_1, rankings_ic, crack_time_given_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "composed-trader",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data_pickle_0_50.pkl', 'rb') as pickle_file:\n",
    "    data_0_50 = pickle.load(pickle_file)\n",
    "data_all = data_0_50\n",
    "with open('data_pickle_50_100.pkl', 'rb') as pickle_file:\n",
    "    data_50_100 = pickle.load(pickle_file)\n",
    "    \n",
    "for i in range(len(data_50_100)):\n",
    "    for k in data_50_100[i]:\n",
    "        data_all[i][k] = data_50_100[i][k]\n",
    "        \n",
    "with open('data_pickle_all.pkl', 'wb') as pickle_file:\n",
    "    pickle.dump(data_all, pickle_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comparative-imperial",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
